# ğŸš— Car Price Prediction with Machine Learning

## ğŸ¯ Project Overview
This project is a machine learning implementation for predicting car prices using various regression algorithms. It is part of the **AICTE OASIS INFOBYTE internship Task 3**.

## ğŸª Objective
The price of a car depends on many factors like brand, features, horsepower, mileage, and more. This project aims to build and train machine learning models that can accurately predict car prices based on these features.

## ğŸ“Š Dataset
- ğŸ”— **Source**: Kaggle - Car Price Prediction (Used Cars)
- ğŸ“ˆ **Size**: 205 records with 26 features
- ğŸ¯ **Target Variable**: Price
- ğŸ·ï¸ **Features Include**: Car ID, Symboling, Car Name, Fuel Type, Aspiration, Door Number, etc.

## ğŸ¤– Models Used

### 1. ğŸ“‰ Linear Regression
- **RÂ² Score**: 0.8407
- **RMSE**: 3546.16
- **MAE**: 2136.78
- **MSE**: 12,575,228.83

### 2. ğŸŒ² Random Forest Regressor (Best Model) â­
- **RÂ² Score**: 0.9553 âœ…
- **RMSE**: 1877.99 â¬‡ï¸
- **MAE**: 1300.25 ğŸ’°
- **MSE**: 3,526,840.27
- **Number of Trees**: 100
- **Max Depth**: 10

## ğŸ” Key Findings
- ğŸš€ **Random Forest significantly outperforms Linear Regression**
- âœ¨ Random Forest achieves an RÂ² score of 0.9553, explaining ~95.53% of variance in car prices
- ğŸ“‰ Reduced prediction error by ~47% compared to Linear Regression (RMSE: 1877.99 vs 3546.16)

## ğŸ“ Project Structure
```
Car-Price-Prediction-ML/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ Task3_CarPricePrediction.py
â””â”€â”€ ğŸ““ notebook.ipynb (Google Colab)
```

## ğŸ› ï¸ Technologies Used
- ğŸ **Python 3** - Programming Language
- ğŸ¼ **Pandas** - Data manipulation
- ğŸ”¢ **NumPy** - Numerical computing
- ğŸ¤– **Scikit-learn** - Machine learning algorithms
- ğŸ“Š **Matplotlib & Seaborn** - Data visualization
- â˜ï¸ **Google Colab** - Development environment

## ğŸ“¦ Installation

```bash
# Install required libraries
pip install pandas numpy scikit-learn matplotlib seaborn
```

## ğŸ’» Usage

```python
# Import libraries and load data
import pandas as pd
from sklearn.ensemble import RandomForestRegressor

# Load and preprocess data
df = pd.read_csv('CarPrice.csv')
# ... preprocessing steps ...

# Train model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions
predictions = model.predict(X_test)
```

## ğŸ† Results Summary
The Random Forest model achieved excellent performance with:
- **95.53% accuracy** (RÂ² Score) ğŸ¯
- **Mean Error**: Â±$1,300 on average ğŸ’µ
- **Root Mean Squared Error**: $1,878 ğŸ“‰

## ğŸš€ Future Improvements
- ğŸ”§ Feature engineering and selection
- âš™ï¸ Hyperparameter tuning
- ğŸ¯ Ensemble methods combining multiple models
- âœ”ï¸ Cross-validation for better generalization
- ğŸ“Š Feature importance analysis

## ğŸ‘¨â€ğŸ’» Author
Shaikjanibasha3450 ğŸ“

## ğŸ“œ License
MIT License

## ğŸ™ Acknowledgments
- ğŸ« AICTE OASIS INFOBYTE Internship Program
- ğŸ“š Kaggle for the dataset
- â˜ï¸ Google Colab for computational resources

---

â­ **If you find this project helpful, please consider giving it a star!** â­
